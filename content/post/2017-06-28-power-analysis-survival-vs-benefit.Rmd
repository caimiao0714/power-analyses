---
title: 'Power analysis: Survival vs Benefit'
author: Jacki Novik (<jackinovik at gmail.com>)
date: '2017-06-28'
slug: power-analysis-survival-vs-benefit
categories: ['survival']
tags: ['immunotherapy']
---

# Why use survival analysis?

There are many reasons to use survival analysis - personally I'm a fan of survival analysis (it's really elegant) so I'm inclined to see the benefits more than the limitations. But for some, the benefits are less than clear.

Granted, there are certain scenarios where one is all but required to use a survival analysis. For example, if you have time-to-event data and a wide range of follow-up times, you will likely obtain [invalid inferences]() from an analysis method that fails to adjust for this differential length of follow-up.

Here, we are **not** discussing that scenario. Instead, we want to assume that we are analyzing, say, data from a randomized controlled trial (RCT) with a design intended to capture at least X days of followup for all patients enrolled, and that the incidence of intervening events is minimal (e.g. little-to-no adverse events necessitating change in treatment, etc).

In this case, one presumably has a choice: which method to use?

- use a survival-type analysis method, where time-to-event is a continuous outcome
- or, to discretize the outcome according to some criteria (say, > X days event-free)

All other things being equal, what are the possible pros/cons of these two approaches? 

1. Many feel that discrete outcome analysis is easier to explain to physicians
2. Many of the current machine-learning techniques require a binary outcome, though this may change
3. On the other hand, discrete outcome analysis "discards good information" about follow-up times. And should therefore have *less statistical power* than a corresponding survival analysis.

**There are other benefits to survival analysis (e.g. less sensitivity to mis-specification of the discretizing criteria), and other comments I could make regarding interpretability. But in this post I want to focus on the power-argument.**

I'm focusing on this because I have most often seen binary outcomes used in service biomarker discovery. By comparison, it's common to use survival analysis to analyze primary results for a RCT. In the case of biomarker discovery this strikes me as particularly problematic since biomarker discovery analyses tend to be [notoriously underpowered]() *[wish I had a reference for this]*, in part due to the expense and difficulty of obtaining biomarker data. But, how much power is lost by using this method?

This is the subject of this analysis. Practically speaking, by how much is the statistical power reduced, if at all, by dichotomizing the survival outcome? And, under what conditions?

## Background

Quite a lot has been written about the shortcomings of dichotomization. Some selected examples:

* This [discussion on Andrew Gelman's blog](http://andrewgelman.com/2015/11/25/gary-mcclelland-agrees-with-me-that-dichotomizing-continuous-variable-is-a-bad-idea-he-also-thinks-my-suggestion-of-dividing-a-variable-into-3-parts-is-also-a-mistake/) regarding his earlier publication ([Gelman and Park, 2008](http://www.stat.columbia.edu/~gelman/research/published/thirds5.pdf)). This discussion concerns the limitations of using a split-at-the-median approach to discretizing of a continuous predictor. Notably, they report a bias introduced by use of a median-split, making a 3-way split preferable. But both methods of discretization lead to a substantial loss of statistical power. 

* A related [post also on Andrew Gelman's blog](http://andrewgelman.com/2014/02/26/econometrics-political-science-epidemiology-etc-dont-model-probability-discrete-outcome-model-underlying-continuous-variable/) discussing a similar question in the context of dependent variables, rather than predictors.

In addition, there is a long history of relevant publications in Statistics and biostatistics in particular. Among them, I would highlight a few:

1. Jacob Cohen, "The Cost of Dichotomization," Applied Psychological Measurement, 1983, Vol. 7, No. 3, pp. 249-253. [https://doi.org/10.1177/014662168300700301](https://doi.org/10.1177/014662168300700301)

2. Chen, Henian, Patricia Cohen and Sophie Chen, "Biased Odds Ratios From Dichotomization of Age", Statistics in Medicine, 2007, Vol. 26, No. 18, pp. 3,487-3,497. [https://doi.org/10.1002/sim.2737](https://doi.org/10.1002/sim.2737)

3. Ragland, David R. “Dichotomizing Continuous Outcome Variables: Dependence of the Magnitude of Association and Statistical Power on the Cutpoint.” Epidemiology, vol. 3, no. 5, 1992, pp. 434–440. JSTOR, www.jstor.org/stable/3702637.

Taken in concert, these references suggest the following:

1. Discretizing a continuous predictor at the mean has a similar effect on statistical power as _reducing the number of cases by 38%_, under the conditions detailed in that analysis. Discretizing both the predictor and the dependent variable is analogous to _reducing number of cases by 60%_ (Cohen, 1983).
2. Discretizing a continuous dependent variable alone can similarly reduce statistical power (Ragland et al, 1992).
3. Discretizing a continuous predictor at its median or mean can introduce _bias into the results_ (Chen et al, 2007; Gelman and Park, 2008).
4. Furthermore, a number of these papers underscore the dangers of optimizing the threshold, either by cherry-picking results at different thresholds or using parameter estimates (e.g. the estimated OR) to determine the ideal or optimal cutpoint (Ragland et al, 1992; Chen et al, 2007).

This deep body of knowledge developed by the statistical community forms the basis for most statistician's intuition that **discretizing otherwise continuous variable is bad practice**. 

However, to my knowledge the net impact on power of using a logistic regression for "benefit" vs a survival analysis has not been reported. A clear description of this will go a long way to quantifying _how bad_ a practice this is.

## Analysis plan

In order to determine the impact of dichotomization in our specific context, we will undertake a simulation study.

[! figure here ]

The analysis will proceed as follows:

- For each analysis type (univariate, multivariate, ??):
  - Draw parameter values for data-simulation
    - baseline hazard for survival
    - censoring time distribution
    - frequency of binary covariate
    - threshold cutoff (as percentile of population survival time)
    - other covariate data & effects, if doing multivariate analysis
  - For each set of parameter values:
    - For each effect size, over a range of effect sizes on the binary covariate `[0, 2]`:
      - For each sample size N, over a range of sample sizes `[20, 100]`:
        - For each of N simulation runs:
          - simulate data
          - prep data & fit model for each model type
            - GLM using MLE + Bayesian MCMC with Stan
            - Survival using CoxPH + Bayesian MCMC with Stan
          - summarize results (NH: effect size <= 0)
    - Plot power over range of sample sizes & effect sizes for the 4 methods.


